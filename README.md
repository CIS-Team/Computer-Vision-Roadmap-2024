# ML
this is comprehensive roadmap for machine learning , deep learning and computer vision .
By : Dr.Mostafa I. Saad

# ML RoadMap

visit the source :
https://youtube.com/playlist?list=PLPt2dINI2MIYdFB4H9bTmen9H6sbSzz2_&si=-Tllise7ll5N2oyH

![image](https://github.com/MohamedTharwat21/ML/assets/109101590/71b2f3a2-ae2a-4115-b3ea-e25744bc7b8d)

# **Roadmap for learning Machine Learning (More focus on DL):**

- General Notes
-- Roadmaps nature

 It is not mandatory when you write  a roadmap  this  meaning that i followed this roadmap literally for many reasons like may be there is update in new courses which is more beneficial than the one i  have studied and so on .

-- Recall DL vs Classical Machine Learning

Try to search about their history 

-- MOOCs assignments.

in the online courses are not enough , generally it tells you to complete some functionalities which are very trivial and easy 

You should do the whole project by yourself , not just some functionalities

**-- Can't understand something ?**
try to search , use GPT ,  and try to find an abstraction for this topic as / a powerpoint/ from high level universities before getting deeper in that topic

**- When to start learning ML**
generally after the second year of your college as you could finish many course in the faculty related to Maths , Programming and so on .


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------


**- Roadmap as following**
- **Andrew Ng Coursera Course .**

- https://www.coursera.org/learn/machine-learning
- https://medium.com/analytics-vidhya/python-implementation-of-andrew-ngs-machine-learning-course-part-1-6b8dd1c73d80

---

- Kaggle
-- Browse S**cikit-learn library** -  use their NN tool (and others if want)

---

S**cikit-learn** Documentation

https://scikit-learn.org/0.18/_downloads/scikit-learn-docs.pdf
--

[https://blogs.mathworks.com/loren/201...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa29XY0JRMXpnMGdOQVJRcnBoNEp1eEgxbl9hUXxBQ3Jtc0trWTVZTmlkR1ZKXy1QNVlaM3lTdDJQVWNja1hOOE0wNlZPeWJISGpIakh6OVRHRnRDM0RDWG05MXZiUEY1ekQ5TU1OYUdIVmh6Vmlld25qQlZYWk1BT2w5bFl5N0JmSlZEdDhBT0xsa2E5TTY3Wm5kSQ&q=https%3A%2F%2Fblogs.mathworks.com%2Floren%2F2015%2F06%2F18%2Fgetting-started-with-kaggle-data-science-competitions%2F&v=qpEjE0blSUA)

-- **Kaggle:  titanic (classification) and Boston housing prices competitions (regression).**

- classification project

[https://www.kaggle.com/c/titanic](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbk9vVFpOc1hNLWQ3U2h4NDRYUkYxQ0pUV2xEZ3xBQ3Jtc0tuckN1Q3JJU240ZGdyODhCN0R2SjM4d1duQnM0bEtkRm9pWjZCY011U0xuZ0JWdHU0c2ZUcVVEWE92REw1aUZfQTlmQ2E1cGhZUjFFdGJFTE0wbUIydGEycWduNjZtdF9UZ2xRa2FOaHRjekRpU0xVdw&q=https%3A%2F%2Fwww.kaggle.com%2Fc%2Ftitanic&v=qpEjE0blSUA)

- Regression project

[https://www.kaggle.com/c/house-prices...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbUNDeW1DRmJCSnNRbVBpSWZxblBQUHJ5UjZEZ3xBQ3Jtc0trV2RrVTN6YmdXLUxPUDE4aXpub3hWTzFHc1pmbWphUzBhWnhWYTJZN2p4RWY0VnlINHdDNnlWMjhYOThJQUUxOXFUeWJCSG5mc3ZPN2lOQ1hXcUs3a0pEVzYzdkJBb1hwTkJSV1czdlpWMnNFeVNnbw&q=https%3A%2F%2Fwww.kaggle.com%2Fc%2Fhouse-prices-advanced-regression-techniques&v=qpEjE0blSUA) 

- Go deeper in **Neural Networks**
-- Why NN?

Try to search about that as NN can do many things without need for the other models 

it can act as classifier and regressor and many other reasons
-- Deeper understanding

 Its very mandatory matter 
--- Backpropagation  

The most important thing you will learn in NN as its great power
--- You may listen to 1 or more lecture of these:
---

 [• Lecture 10 - Neur...](https://www.youtube.com/watch?v=Ih5Mr93E-2c)

!https://www.gstatic.com/youtube/img/watch/yt_favicon.png

---

 [• 12a: Neural Nets](https://www.youtube.com/watch?v=uXt8qF2Zzfo&t=0s)

!https://www.gstatic.com/youtube/img/watch/yt_favicon.png

---

 [• Lecture 4 | Intro...](https://www.youtube.com/watch?v=d14TUNcbn1k&t=0s)

!https://www.gstatic.com/youtube/img/watch/yt_favicon.png

Great practice :

--- On paper: Compute/Trace an example:

[https://mattmazur.com/2015/03/17/a-st...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbFRJRm1naVl2aXVkZWo2cU4yUEpNQ3lJSHZvQXxBQ3Jtc0ttbGl2cGxtbW9jYjZ5Nm9YS291WXV1S084UG93MnRlUzMxSGVjS2lZRURGMFJMOVlvSWJzbjNNS3VIMjB6aVhZcy12T3Q4eGw0ZE56cE9vQnpacjlMSWhRcXp5eENaZHRRTVNDTnJ3TUR5TTBzWnJXUQ&q=https%3A%2F%2Fmattmazur.com%2F2015%2F03%2F17%2Fa-step-by-step-backpropagation-example%2F&v=qpEjE0blSUA)

-- Reimplement NN from scratch
--- Multi-class classification (softmax)
--- Multi-label classification (sigmoid)
--- Regression
--- Try AE with your network (AutoEncoder)
-- Learn dropout and implement it

-- FYI: NN/ML Arabic playlist:

 [• Neural Networks I...](https://www.youtube.com/playlist?list=PLQkyODvJ8ywsLydDYORIlJxV9KarhXp9O)

!https://www.gstatic.com/youtube/img/watch/yt_favicon.png

-- Maybe read NN chapter from a book
 
- Evaluation metrics [https://towardsdatascience.com/metric...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbWVia0tZZ0NTWVFKb25kUmNERzBtZ0U0Y2phUXxBQ3Jtc0tuTm5KME1XSF9FclZWSHNQdmdrY3dRWmtXemU4SzFhbFF5UmtFT1NaS2tsQlJkWE12cjNYNEpLQm9qcEhpTlFTaEpuN09CYkNqVmctZjdYRU9rSUdEdXF2Tm1mSFRReEdqd3MyeUF6VXJQMVktTFQ4UQ&q=https%3A%2F%2Ftowardsdatascience.com%2Fmetrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234&v=qpEjE0blSUA)

-- Later: (when you start computer vision)

[https://medium.com/@jonathan_hui/map-...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbE9KWFlVVVlHdUo4V3ZncDFVOVZ2WUpadXB4QXxBQ3Jtc0tuZGlEQWw2bTNMMWlnczc1ZjhVdlBGbjZrQmY5MlJjY0RTWTN3NmhmLTNaYjhoTWNUVWJ2bk15YUJObDJlX0RXZE1xenhtS1RZOHQ5NEJVM1VBSG5YNmFRc1pKSUFENzQyMzdnWGtmaHl4dENRT05iOA&q=https%3A%2F%2Fmedium.com%2F%40jonathan_hui%2Fmap-mean-average-precision-for-object-detection-45c121a31173&v=qpEjE0blSUA)

- AFTER you finish the above, do the following time split strategy
**- Next 25% of time for classical Machine Learning models like SVM and so on / projects - 75% for deep learning** 

CNN and RNN    
****
- 25% of your time for classical ML will be in 
-- kaggle projects / Kaggle blogs
--

[https://www.coursera.org/specializati...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbnl6V1lzRHZyeXprUFVEZUxwYUhlbHdiaU40Z3xBQ3Jtc0tsT19RbmY0aG9LakpPTWtYclpxYnJzdUQxQW1YS1dxMVR1bDJMeXNBZ1lQWjlRMzRqeTgyVzlkLXdOZVZiaE96VElNdGRzVHBlR3NrdUY1S2UyZmVrWjRaSzlkNW9tMG1VRFNocTYtYUprQnV5ZTlPMA&q=https%3A%2F%2Fwww.coursera.org%2Fspecializations%2Faml&v=qpEjE0blSUA)

-- Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists

- 75% of your time for deep learning
--

[https://www.coursera.org/specializati...](https://www.deeplearning.ai/courses/deep-learning-specialization/)

---

 [/ @deeplearningai](https://www.youtube.com/channel/UCcIXc5mJsHVYTZR1maL5l9w/playlists/playlists)

!https://www.gstatic.com/youtube/img/watch/yt_favicon.png

-- [FYI]

[https://classroom.udacity.com/courses...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqblNXdFk2WHFaRWVaY0xZUW16VTE3Q3dkQ3pJUXxBQ3Jtc0tuMmZJZzB6N1R3MmFycEJFcmhsdU9TYVE0Z3FPM01acXRTYncxY0ZYb2ZIeVNDNWlvNmZEeEQ0Y0xBSm1UVVZtY1c2NFdwLTkwVVJqMnhPbU51eGNlOXN5ZWRmY1V0NUFlT1E3bmxhdTRDbWg0NnltVQ&q=https%3A%2F%2Fclassroom.udacity.com%2Fcourses%2Fud730&v=qpEjE0blSUA)

-- Frameworks (TF/Pytorch) - study while learning
-- Either learn 2D vision or nlp (later after work learn 2nd)
--- Vision key problems: classification, detection, segmentation, pose estimation, object traction, action detection/recognition
--- stanford  courses
---- Computer Vision:

[http://cs231n.stanford.edu/syllabus.html](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbVRYanppT2JYMXZUaTl4eVZGZkFmaFYzdjRLZ3xBQ3Jtc0tuYXcyak9ZbjRZc1F4YngzaXFrZ0tpYUd6QmJ0SzRWTHMwT1BXS3FvLWd3UG50bmhWRXhhYklXT3MxZENxRkRDaDVwSjJFbUduLWRSQmljWE1neUkyU3YxV2ItcVRHT29vc1Q1djBJOG5uZzV4T3poMA&q=http%3A%2F%2Fcs231n.stanford.edu%2Fsyllabus.html&v=qpEjE0blSUA)

---- NLP:

[http://web.stanford.edu/class/cs224n/](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqblp0RVExeXdKTGVwWERIeFduaDIyVXZKalJTQXxBQ3Jtc0tsS2xRNzFMYm5XV3dTNDFYaHVvTHBMdFdoNjhDdmFvMXdJYk4wVlduS084YjdMLUpFTE1SczB4RUlzamtqT0xNQ2FRa0xtdlFsclBCU1pGaTBiNXhqRUZka25hWTlhWllLMW9ITzhWUDV3QjNpN3lqVQ&q=http%3A%2F%2Fweb.stanford.edu%2Fclass%2Fcs224n%2F&v=qpEjE0blSUA)

- More on the road
-- ML book, e.g. Bishop
-- Understand more models, fields, more experience
-- Field follow up: E.g. in Vision (CVPR, ICCV, ECCV)
-- DL Experience: Paper-to-code skill
-- Vision elements (later):

[https://classroom.udacity.com/courses...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbldLcmhMRmJUVjVITHZfYWxSWmJGMXgwbGl5QXxBQ3Jtc0tsaEhvajNuOGFyQXM1MEU2dEtFUVlnOXhyeUZMeExDNENEUHhSOGs2U2VyYzZPYkZWcWd6THhDSC10TmphSXdrdzVNVFJVNDJxME1rRUNQd3Nwb0h1c2VrUDFWaXJEOGZ6TGlVUHF3UzRrRVRaemZTUQ&q=https%3A%2F%2Fclassroom.udacity.com%2Fcourses%2Fud810&v=qpEjE0blSUA)

-- Abstracting skills
  
- Other ML areas (later)
-- Generative models
--- PGM, EM (GMM), VI, MCMC
--- DL: VAE (variational autoencoder), GAN -(Study GAN)
----

[https://medium.com/@jonathan_hui/gan-...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbWRUa3RNdzhreENkSEdOcEVDdXB2TmlPTDRGUXxBQ3Jtc0ttZFhrSXdOa3BmSkoxRDBYRUx5RmxDSnMwUGRIWGRxMXlxVm1DOFBYMlU0T1FrRWRrQ1JZdlJ6MUt0ZTBkVEtHdHppdXJteDhoSE1KQWR6UUYxUUNCRnlCMG5zZ0xSYXFJRUc3UGUwczc2WjV4NkRvRQ&q=https%3A%2F%2Fmedium.com%2F%40jonathan_hui%2Fgan-some-cool-applications-of-gans-4c9ecca35900&v=qpEjE0blSUA)

----

[https://github.com/nashory/gans-aweso...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbHFTdXNuVmx1UUVvLXl6SlMtMnBsc3pXRTctd3xBQ3Jtc0ttblpzeTlxOFVOZDlFZDRPSGdfUFUxc2FWZXg5UEY5ck5LRkoxNi11TDdNVFJ5a1Qwa2poMEo2UjhtLThiN0tzeEJJaEtOTHhQQ1Jra2Q0cWN5aGtyVEQxQUQ3R2V3dFkxZHRiOEVaLUZVOEJsTUtwOA&q=https%3A%2F%2Fgithub.com%2Fnashory%2Fgans-awesome-applications&v=qpEjE0blSUA)

-- Reinforcement Learning

--------
Updates/Additions
-----
- What if you are also interested in competitive programming?
-- ML is time-consuming to be good. In this case, divide your vacation to 50% competitive and 50% for ML
